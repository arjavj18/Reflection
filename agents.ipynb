{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "neo4j_password = os.getenv('NEO4J_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"neo4j://localhost:7687\", auth=(\"neo4j\", neo4j_password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_nodes(node_name):\n",
    "    # Define the Cypher query to find connected nodes and return both Name and Desc properties\n",
    "    query = \"\"\"\n",
    "    MATCH (n {Name: $node_name})-[:PARENT_OF]-(connected_nodes)\n",
    "    RETURN connected_nodes.Name AS name, connected_nodes.Desc AS desc\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query\n",
    "    results = graph.run(query, node_name=node_name)\n",
    "    \n",
    "    # Extract the Name and Desc of each connected node\n",
    "    connected_nodes_info = []\n",
    "    for record in results:\n",
    "        name = record[\"name\"]\n",
    "        desc = record[\"desc\"]\n",
    "        connected_nodes_info.append({\"Name\": name, \"Desc\": desc})\n",
    "    \n",
    "    return connected_nodes_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"current_output\", description=\"Output from the current agent that will be passed to the next agent. If there is no next agent, put None\"),\n",
    "    ResponseSchema(name=\"next_agent\", description=\"The next agent to handle the request.\"),\n",
    "    ResponseSchema(name=\"next_task\", description=\"The task or action for the next agent.\"),\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a highly skilled assistant designed to search and answer user's general queries\n",
    "            Given a list of connected agents with their names and description, if required return the name of the next agent you require for your assistance as well as give an instruction for it.\n",
    "               List of agents : {Connected_agents}\\n\n",
    "               Format Instructions : {format_instructions}\"\"\"\n",
    "\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "greeting_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a friendly AI that greets people warmly when they start a conversation and says goodbye appropriately when they mention leaving. \n",
    "\n",
    "                If someone says something about going away, respond with a proper goodbye.\n",
    "                If they just greet you or talk normally, respond with a friendly greeting.\n",
    "                Given a list of connected agents with their names and description, if required return the name of the next agent you require for your assistance as well as give an instruction for it.\n",
    "               List of agents : {Connected_agents} \\n\n",
    "               Format Instructions : {format_instructions}\"\"\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "math_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a highly skilled assistant with expertise in solving math problems. Ensure accurate calculations and provide clear explanations for mathematical concepts. Use the tavily_search_results_json tool for additional information if needed.\n",
    "                Given a list of connected agents with their names and description, if required return the name of the next agent you require for your assistance as well as give an instruction for it.\n",
    "               List of agents : {Connected_agents} \\n\n",
    "               Format Instructions : {format_instructions}\"\"\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an AI assistant with access to powerful tools for calculations. Use these calculation tools when you need to perform precise calculations. \n",
    "               Given a list of connected agents with their names and description, if required return the name of the next agent you require for your assistance as well as give an instruction for it.\n",
    "               List of agents : {Connected_agents} \\n\n",
    "               Format Instructions : {format_instructions}\"\"\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "supervisor_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an AI assistant who is the first agent tasked to find the appropriate next agent given the task. \n",
    "               Given a list of connected agents with their names and description, if required return the name of the next agent you require for your assistance as well as give an instruction for it.\n",
    "               List of agents : {Connected_agents} \\n\n",
    "               Format Instructions : {format_instructions}\"\"\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(tavily_api_key = TAVILY_API_KEY)\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent2 = create_tool_calling_agent(llm, tools, search_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor = create_tool_calling_agent(llm, tools, supervisor_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent21 = create_tool_calling_agent(llm, tools=tools, prompt= greeting_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Generally good at math questions\n",
    "agent1 = create_tool_calling_agent(\n",
    "    llm=llm,\n",
    "    tools=[search],\n",
    "    prompt=math_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent11 = create_tool_calling_agent(\n",
    "    llm=llm,\n",
    "    tools=[search],\n",
    "    prompt=tool_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "choosing_template = \"\"\"\n",
    "You are an agent with multiple other AI agents for your assistance.\n",
    "\n",
    "AI: \n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt template\n",
    "choosing_prompt = PromptTemplate(input_variables=[\"Connected_agents\"], template=choosing_template, partial_variables={\"format_instructions\": format_instructions})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
